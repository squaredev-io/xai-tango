digraph {
	graph [size="13.65,13.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5497272064 [label="
 ()" fillcolor=darkolivegreen1]
	11226263760 -> 5143115440 [dir=none]
	5143115440 [label="self
 (1, 2)" fillcolor=orange]
	11226263760 [label="MeanBackward0
------------------------------
self          : [saved tensor]
self_sym_sizes:         (1, 2)"]
	11226265200 -> 11226263760
	11226265200 -> 5497266624 [dir=none]
	5497266624 [label="mat1
 (1, 128)" fillcolor=orange]
	11226265200 -> 5497272384 [dir=none]
	5497272384 [label="mat2
 (128, 2)" fillcolor=orange]
	11226265200 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (1, 128)
mat1_sym_strides:       (128, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :       (128, 2)
mat2_sym_strides:       (1, 128)"]
	11226263856 -> 11226265200
	5497273824 [label="fc2/Gemm.bias
 (2)" fillcolor=lightblue]
	5497273824 -> 11226263856
	11226263856 [label=AccumulateGrad]
	11226267312 -> 11226265200
	11226267312 -> 5497267664 [dir=none]
	5497267664 [label="result
 (1, 128)" fillcolor=orange]
	11226267312 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	11226263376 -> 11226267312
	11226263376 -> 11225798272 [dir=none]
	11225798272 [label="mat1
 (1, 32768)" fillcolor=orange]
	11226263376 -> 5497269664 [dir=none]
	5497269664 [label="mat2
 (32768, 128)" fillcolor=orange]
	11226263376 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (1, 32768)
mat1_sym_strides:     (32768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :   (32768, 128)
mat2_sym_strides:     (1, 32768)"]
	11226259920 -> 11226263376
	5497273104 [label="fc1/Gemm.bias
 (128)" fillcolor=lightblue]
	5497273104 -> 11226259920
	11226259920 [label=AccumulateGrad]
	11226266352 -> 11226263376
	11226266352 [label="ReshapeAliasBackward0
-------------------------------
self_sym_sizes: (1, 32, 32, 32)"]
	11226260256 -> 11226266352
	11226260256 -> 5497269504 [dir=none]
	5497269504 [label="result1
 (1, 32, 32, 32)" fillcolor=orange]
	11226260256 -> 11059055664 [dir=none]
	11059055664 [label="self
 (1, 32, 64, 64)" fillcolor=orange]
	11226260256 [label="MaxPool2DWithIndicesBackward0
-----------------------------
ceil_mode  :          False
dilation   :         (1, 1)
kernel_size:         (2, 2)
padding    :         (0, 0)
result1    : [saved tensor]
self       : [saved tensor]
stride     :         (2, 2)"]
	11226261408 -> 11226260256
	11226261408 -> 5497270704 [dir=none]
	5497270704 [label="result
 (1, 32, 64, 64)" fillcolor=orange]
	11226261408 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	11226259008 -> 11226261408
	11226259008 -> 11222019008 [dir=none]
	11222019008 [label="input
 (1, 16, 64, 64)" fillcolor=orange]
	11226259008 -> 5497272864 [dir=none]
	5497272864 [label="weight
 (32, 16, 3, 3)" fillcolor=orange]
	11226259008 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (32,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11226261072 -> 11226259008
	11226261072 -> 5497269584 [dir=none]
	5497269584 [label="result1
 (1, 16, 64, 64)" fillcolor=orange]
	11226261072 -> 11059064064 [dir=none]
	11059064064 [label="self
 (1, 16, 128, 128)" fillcolor=orange]
	11226261072 [label="MaxPool2DWithIndicesBackward0
-----------------------------
ceil_mode  :          False
dilation   :         (1, 1)
kernel_size:         (2, 2)
padding    :         (0, 0)
result1    : [saved tensor]
self       : [saved tensor]
stride     :         (2, 2)"]
	11226267264 -> 11226261072
	11226267264 -> 5497270144 [dir=none]
	5497270144 [label="result
 (1, 16, 128, 128)" fillcolor=orange]
	11226267264 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	11226260496 -> 11226267264
	11226260496 -> 11225797392 [dir=none]
	11225797392 [label="input
 (1, 1, 128, 128)" fillcolor=orange]
	11226260496 -> 5497270864 [dir=none]
	5497270864 [label="weight
 (16, 1, 3, 3)" fillcolor=orange]
	11226260496 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (16,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11226263904 -> 11226260496
	5497270864 [label="conv1/Conv.weight
 (16, 1, 3, 3)" fillcolor=lightblue]
	5497270864 -> 11226263904
	11226263904 [label=AccumulateGrad]
	11226259488 -> 11226260496
	5497273024 [label="conv1/Conv.bias
 (16)" fillcolor=lightblue]
	5497273024 -> 11226259488
	11226259488 [label=AccumulateGrad]
	11226262560 -> 11226259008
	5497272864 [label="conv2/Conv.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	5497272864 -> 11226262560
	11226262560 [label=AccumulateGrad]
	11226267360 -> 11226259008
	5497272944 [label="conv2/Conv.bias
 (32)" fillcolor=lightblue]
	5497272944 -> 11226267360
	11226267360 [label=AccumulateGrad]
	11226263088 -> 11226263376
	11226263088 [label=TBackward0]
	11226263184 -> 11226263088
	5497270784 [label="fc1/Gemm.weight
 (128, 32768)" fillcolor=lightblue]
	5497270784 -> 11226263184
	11226263184 [label=AccumulateGrad]
	11226266016 -> 11226265200
	11226266016 [label=TBackward0]
	11226260592 -> 11226266016
	5497274144 [label="fc2/Gemm.weight
 (2, 128)" fillcolor=lightblue]
	5497274144 -> 11226260592
	11226260592 [label=AccumulateGrad]
	11226263760 -> 5497272064
}
