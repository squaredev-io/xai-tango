digraph {
	graph [size="14.549999999999999,14.549999999999999"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	11440139040 [label="
 ()" fillcolor=darkolivegreen1]
	11087388704 -> 11440138960 [dir=none]
	11440138960 [label="self
 (1, 2)" fillcolor=orange]
	11087388704 [label="MeanBackward0
------------------------------
self          : [saved tensor]
self_sym_sizes:         (1, 2)"]
	11087388848 -> 11087388704
	11087388848 -> 11440138880 [dir=none]
	11440138880 [label="mat1
 (1, 128)" fillcolor=orange]
	11087388848 -> 11440140000 [dir=none]
	11440140000 [label="mat2
 (128, 2)" fillcolor=orange]
	11087388848 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (1, 128)
mat1_sym_strides:       (128, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :       (128, 2)
mat2_sym_strides:       (1, 128)"]
	11087388992 -> 11087388848
	11087007888 [label="fc2/Gemm.bias
 (2)" fillcolor=lightblue]
	11087007888 -> 11087388992
	11087388992 [label=AccumulateGrad]
	11087388800 -> 11087388848
	11087388800 -> 11440140160 [dir=none]
	11440140160 [label="result
 (1, 128)" fillcolor=orange]
	11087388800 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	11087389040 -> 11087388800
	11087389040 -> 11440138800 [dir=none]
	11440138800 [label="mat1
 (1, 32768)" fillcolor=orange]
	11087389040 -> 11440140400 [dir=none]
	11440140400 [label="mat2
 (32768, 128)" fillcolor=orange]
	11087389040 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (1, 32768)
mat1_sym_strides:     (32768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :   (32768, 128)
mat2_sym_strides:     (1, 32768)"]
	11087389232 -> 11087389040
	11087007728 [label="fc1/Gemm.bias
 (128)" fillcolor=lightblue]
	11087007728 -> 11087389232
	11087389232 [label=AccumulateGrad]
	11087389184 -> 11087389040
	11087389184 [label="ReshapeAliasBackward0
----------------------------
self_sym_sizes: (32, 32, 32)"]
	11087388608 -> 11087389184
	11087388608 -> 11440140800 [dir=none]
	11440140800 [label="result1
 (32, 32, 32)" fillcolor=orange]
	11087388608 -> 11440138720 [dir=none]
	11440138720 [label="self
 (32, 64, 64)" fillcolor=orange]
	11087388608 [label="MaxPool2DWithIndicesBackward0
-----------------------------
ceil_mode  :          False
dilation   :         (1, 1)
kernel_size:         (2, 2)
padding    :         (0, 0)
result1    : [saved tensor]
self       : [saved tensor]
stride     :         (2, 2)"]
	11087388416 -> 11087388608
	11087388416 -> 11440140640 [dir=none]
	11440140640 [label="result
 (32, 64, 64)" fillcolor=orange]
	11087388416 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	11087388320 -> 11087388416
	11087388320 [label="SqueezeBackward1
-------------------------------
dim           :               0
self_sym_sizes: (1, 32, 64, 64)"]
	11087388224 -> 11087388320
	11087388224 -> 11440140720 [dir=none]
	11440140720 [label="input
 (1, 16, 64, 64)" fillcolor=orange]
	11087388224 -> 11087007568 [dir=none]
	11087007568 [label="weight
 (32, 16, 3, 3)" fillcolor=orange]
	11087388224 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (32,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11087388128 -> 11087388224
	11087388128 [label="UnsqueezeBackward0
------------------
dim: 0"]
	11087387936 -> 11087388128
	11087387936 -> 11440141040 [dir=none]
	11440141040 [label="result1
 (16, 64, 64)" fillcolor=orange]
	11087387936 -> 11440138480 [dir=none]
	11440138480 [label="self
 (16, 128, 128)" fillcolor=orange]
	11087387936 [label="MaxPool2DWithIndicesBackward0
-----------------------------
ceil_mode  :          False
dilation   :         (1, 1)
kernel_size:         (2, 2)
padding    :         (0, 0)
result1    : [saved tensor]
self       : [saved tensor]
stride     :         (2, 2)"]
	11087387840 -> 11087387936
	11087387840 -> 11440140880 [dir=none]
	11440140880 [label="result
 (16, 128, 128)" fillcolor=orange]
	11087387840 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	11087387744 -> 11087387840
	11087387744 [label="SqueezeBackward1
---------------------------------
dim           :                 0
self_sym_sizes: (1, 16, 128, 128)"]
	11087387648 -> 11087387744
	11087387648 -> 11440141680 [dir=none]
	11440141680 [label="input
 (1, 1, 128, 128)" fillcolor=orange]
	11087387648 -> 11087007408 [dir=none]
	11087007408 [label="weight
 (16, 1, 3, 3)" fillcolor=orange]
	11087387648 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (16,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11087387552 -> 11087387648
	11087007408 [label="conv1/Conv.weight
 (16, 1, 3, 3)" fillcolor=lightblue]
	11087007408 -> 11087387552
	11087387552 [label=AccumulateGrad]
	11087387600 -> 11087387648
	11087007488 [label="conv1/Conv.bias
 (16)" fillcolor=lightblue]
	11087007488 -> 11087387600
	11087387600 [label=AccumulateGrad]
	11087388176 -> 11087388224
	11087007568 [label="conv2/Conv.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	11087007568 -> 11087388176
	11087388176 [label=AccumulateGrad]
	11087388512 -> 11087388224
	11087007648 [label="conv2/Conv.bias
 (32)" fillcolor=lightblue]
	11087007648 -> 11087388512
	11087388512 [label=AccumulateGrad]
	11087389136 -> 11087389040
	11087389136 [label=TBackward0]
	11087388368 -> 11087389136
	11087007328 [label="fc1/Gemm.weight
 (128, 32768)" fillcolor=lightblue]
	11087007328 -> 11087388368
	11087388368 [label=AccumulateGrad]
	11087388944 -> 11087388848
	11087388944 [label=TBackward0]
	11087388464 -> 11087388944
	11087007808 [label="fc2/Gemm.weight
 (2, 128)" fillcolor=lightblue]
	11087007808 -> 11087388464
	11087388464 [label=AccumulateGrad]
	11087388704 -> 11440139040
}
